"""
SahibindenSniper - Parser Module
HTML iÃ§erikten Ã¼rÃ¼n verilerini Ã§Ä±karma
"""

import re
import logging
from bs4 import BeautifulSoup

# Logger setup
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger(__name__)

BASE_URL = "https://www.sahibinden.com"


def clean_price(price_text: str) -> int:
    """
    Fiyat stringini temizleyip integer'a Ã§evirir.
    Ã–rnek: "10.500 TL" -> 10500
    
    Args:
        price_text: Ham fiyat metni
    
    Returns:
        TemizlenmiÅŸ fiyat (int)
    """
    # Sadece rakamlarÄ± al
    digits = re.sub(r"[^\d]", "", price_text)
    return int(digits) if digits else 0


def parse_listings(html_content: str) -> list[dict]:
    """
    Sahibinden HTML'inden Ã¼rÃ¼n listesini parse eder.
    
    Args:
        html_content: Ham HTML iÃ§erik
    
    Returns:
        ÃœrÃ¼n listesi: [{"id": str, "title": str, "price": int, "link": str}, ...]
    """
    listings = []
    
    try:
        soup = BeautifulSoup(html_content, "html.parser")
        rows = soup.find_all("tr", class_="searchResultsItem")
        
        logger.info(f"ğŸ“‹ {len(rows)} ilan satÄ±rÄ± bulundu.")
        
        for row in rows:
            try:
                # ID
                listing_id = row.get("data-id")
                if not listing_id:
                    continue
                
                # BaÅŸlÄ±k ve Link
                title_elem = row.find("a", class_="classifiedTitle")
                if not title_elem:
                    logger.warning(f"âš  BaÅŸlÄ±k bulunamadÄ±: {listing_id}")
                    continue
                
                title = title_elem.get_text(strip=True)
                link = title_elem.get("href", "")
                
                # Link'e domain ekle
                if link and not link.startswith("http"):
                    link = BASE_URL + link
                
                # Fiyat
                price_elem = row.find("td", class_="searchResultsPriceValue")
                if price_elem:
                    price_text = price_elem.get_text(strip=True)
                    price = clean_price(price_text)
                else:
                    price = 0
                    logger.warning(f"âš  Fiyat bulunamadÄ±: {listing_id}")
                
                listings.append({
                    "id": listing_id,
                    "title": title,
                    "price": price,
                    "link": link
                })
                
            except Exception as e:
                logger.error(f"âœ— SatÄ±r parse hatasÄ±: {e}")
                continue
        
        logger.info(f"âœ“ {len(listings)} ilan baÅŸarÄ±yla parse edildi.")
        
    except Exception as e:
        logger.error(f"âœ— HTML parse hatasÄ±: {e}")
    
    return listings


if __name__ == "__main__":
    # Test: sahibinden_raw.html dosyasÄ±nÄ± oku ve parse et
    try:
        with open("sahibinden_raw.html", "r", encoding="utf-8") as f:
            html = f.read()
        
        logger.info("ğŸ“‚ sahibinden_raw.html okundu.")
        
        listings = parse_listings(html)
        
        print("\n" + "=" * 60)
        print(f"ğŸ“Š TOPLAM: {len(listings)} ilan")
        print("=" * 60)
        
        for i, item in enumerate(listings[:10], 1):  # Ä°lk 10 ilan
            print(f"\n[{i}] ID: {item['id']}")
            print(f"    BaÅŸlÄ±k: {item['title'][:50]}...")
            print(f"    Fiyat: {item['price']:,} TL")
            print(f"    Link: {item['link']}")
        
        if len(listings) > 10:
            print(f"\n... ve {len(listings) - 10} ilan daha.")
            
    except FileNotFoundError:
        logger.error("âœ— sahibinden_raw.html bulunamadÄ±. Ã–nce scraper.py veya main.py Ã§alÄ±ÅŸtÄ±rÄ±n.")
